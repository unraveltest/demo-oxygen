<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE task
  PUBLIC "-//OASIS//DTD DITA Task//EN" "task.dtd" >
<task xml:lang="en-us" id="FCFGHGGB">
   <title>Part 3: Install Unravel Spark Sensor on New or Existing Qubole Spark
      Cluster </title>
   <taskbody>
      <context>
         <p>Introduction</p>
         <p>Unravel Sensor can collect information about Spark applications. This guide describes how to install Unravel
            Sensor for Qubole-based Spark clusters. The information here applies to Spark versions 1.5.x through 2.0.x
            and Unravel 3.4-4.1. Highlighted text indicates where you must substitute your particular values.</p>
         <ph outputclass="aui-icon aui-icon-small aui-iconfont-info confluence-information-macro-icon"/>
         <p>
            <ph>
               <codeph>HIGHLIGHTED</codeph>
            </ph> text and text with brackets ( { } ), unless otherwise noted, indicates where you must substitute your
            particular values for the text.</p>
         <p>
            <ph>
               <codeph>UNRAVEL_HOST_IP</codeph>
            </ph>must be a fully qualified DNS or the IP address.</p>
         <p>
            <ph>
               <ph>
                  <ph>
                     <ph>
                        <ph>
                           <codeph>PATH_TO_SENSOR_JARS</codeph>
                        </ph>
                     </ph>
                  </ph>
               </ph>
            </ph>: <ph>
               <ph>is the absolute path to the location of the sensor jars.</ph>
            </ph>
         </p>
         <p>
            <ph> </ph>
            <ph/>
         </p>
         <p>Add Unravel Spark Instrumentation to New Qubole Spark Cluster</p>
         <ol>
            <li>
               <p>
                  <ph outputclass="confluence-anchor-link"/>Configure<b> </b>Unravel s3 read-only credentials in
                     <codeph>/usr/local/unravel/etc/s3ro.properties</codeph> as follows:</p>
               <ph outputclass="aui-icon aui-icon-small aui-iconfont-info confluence-information-macro-icon"/>
               <p>This sample <codeph>s3ro.properties</codeph> file has multiple s3 profiles and access keys.</p>
               <codeblock outputclass="syntaxhighlighter-pre">[default]
aws_access_key_id = {ACCESS_KEY_VALUE1}
aws_secret_access_key = {SECRET_KEY_VALUE1}

[profile_name_2]
aws_access_key_id = {ACCESS_KEY_VALUE2}
aws_secret_access_key = {SECRET_KEY_VALUE2}</codeblock>
               <p outputclass="auto-cursor-target">
                  <i>Note: Substitute actual values for ACCESS_KEY_VALUEx and SECRET_KEY_VALUEx.</i>
               </p>
               <p/>
            </li>
            <li>
               <p>Edit <codeph>/usr/local/unravel/etc/unravel.properties</codeph> so that Unravel Server incorporates
                     <codeph>s3ro.properties</codeph>:</p>
               <codeblock outputclass="syntaxhighlighter-pre">com.unraveldata.s3.profile.config.file.path=/usr/local/unravel/etc/s3ro.properties
com.unraveldata.spark.s3.profilesToBuckets=&lt;default&gt;:&lt;s3ro_bucket1&gt;,&lt;profile_name_2&gt;:&lt;s3r0_bucket2&gt;</codeblock>
            </li>
            <li>
               <p outputclass="auto-cursor-target">Restart the Unravel ETL daemon(s):</p>
               <codeblock outputclass="syntaxhighlighter-pre"># sudo /etc/init.d/unravel_all.sh stop-etl
# sudo /etc/init.d/unravel_all.sh start</codeblock>
            </li>
            <li>Ensure ports 3000 (for web UI access) and 4043 (from cluster) are open for incoming traffic. These
               should <b>not</b> be open to the public Internet.<!--A BR tag was used here in the original source.-->
            </li>
            <li>
               <p outputclass="auto-cursor-target">Verify that port 3000 is open by running a <codeph>curl</codeph>
                  command from a potential Unravel user machine as follows :</p>
               <ph outputclass="aui-icon aui-icon-small aui-iconfont-approve confluence-information-macro-icon"/>
               <p>If the version information is not visible (request timeout), then adjust security groups, firewalls,
                  etc. and try again. For VPCs, it might be necessary to add a route.</p>
               <codeblock outputclass="syntaxhighlighter-pre"># curl http://{UNRAVEL_HOST_IP}:3000/version.txt</codeblock>
            </li>
            <li>
               <p outputclass="auto-cursor-target">Copy the Unravel Spark bootstrap file from Unravel Server to your
                  Spark Qubole cluster, using <codeph>curl</codeph>:</p>
               <codeblock outputclass="syntaxhighlighter-pre"># curl http://{UNRAVEL_HOST_IP}:3000/hh/unraveldata-clients/unravel_qubole_bootstrap.sh &gt; unravel_qubole_bootstrap.sh</codeblock>
               <p outputclass="auto-cursor-target">
                  <i>Note: Substitute the actual host for UNRAVEL_HOST_IP.</i>
               </p>
               <p outputclass="auto-cursor-target">
                  <i/>
               </p>
            </li>
            <li>
               <p outputclass="auto-cursor-target">Copy Unravel Spark bootstrap file to your s3://<ph>
                     <ph>
                        <codeph>Bootstrap_location_for_Spark Qubole Cluster</codeph>
                     </ph>
                  </ph>
               </p>
               <codeblock outputclass="syntaxhighlighter-pre">aws s3 cp unravel_qubole_bootstrap.sh s3://{Bootstrap_location_for_Spark Qubole cluster}/unravel_qubole_bootstrap.sh</codeblock>
            </li>
            <li>In Qubole’s <b>Edit Cluster Setting</b>, if you <u>
                  <b>do not</b>
               </u> have your own customized Node Bootstrap file, add <codeph>unravel_qubole_bootstrap.sh</codeph> into
               this field as shown in the diagram:<!--A BR tag was used here in the original source.-->
               <ph outputclass="confluence-embedded-file-wrapper confluence-embedded-manual-size">
                  <image href="media/52620138.png"
                     outputclass="confluence-embedded-image confluence-content-image-border"/>
               </ph>
            </li>
            <li>In Qubole, scripts do not take input parameters. Therefore, Unravel's bootstrap script takes all the
               required parameters from the Hadoop configuration. You can customize your Hadoop configuration through
               specific parameters within the <b>Override Hadoop Configuration Variables</b> section as shown in the
               diagram below. As you can see, <b>unravel-bootstrap </b>is the property name you must use prepend to all
               configuration parameters relevant to Unravel. <!--A BR tag was used here in the original source.--><!--A BR tag was used here in the original source.-->
               <i>Note: Separate parameters with commas.</i><!--A BR tag was used here in the original source.--><!--A BR tag was used here in the original source.-->
               <ph outputclass="confluence-embedded-file-wrapper confluence-embedded-manual-size">
                  <image href="media/52620160.png"
                     outputclass="confluence-embedded-image confluence-content-image-border"/>
               </ph>
            </li>
            <li>
               <p outputclass="auto-cursor-target">Add these settings to <codeph>unravel-bootstrap</codeph> for Spark
                  clusters:</p>
               <codeblock outputclass="syntaxhighlighter-pre">unravel-bootstrap=UNRAVEL_SERVER=UNRAVEL_HOST_AND_PORT, SPARK_VER_XYZ=SPARK_VER_XYZ[,SPARK_APP_LOAD_MODE=SPARK_APP_LOAD_MODE,WRAPPED_SCRIPT=WRAPPED_SCRIPT]</codeblock>
               <p>
                  <ph>
                     <codeph>
                        <ph>
                           <ph>
                              <ph>
                                 <ph>
                                    <ph>
                                       <codeph>
                                          <ph>SPARK_VERSION<ph>
                                                <ph>
                                                   <codeph>_X.Y.Z</codeph>
                                                </ph>
                                             </ph>
                                          </ph>
                                       </codeph>
                                    </ph>
                                    <ph>
                                       <ph> - target Spark version (eg. 1.3.0, 1.6.0, 2.0.1, etc.)</ph>
                                    </ph>
                                 </ph>
                              </ph>
                           </ph>
                        </ph>
                     </codeph>
                  </ph>
               </p>
               <p outputclass="title">Note:</p>
               <p>
                  <ph>
                     <codeph>The parameters in square brackets [ ] above are optional. Their meanings are:</codeph>
                  </ph>
               </p>
               <p>
                  <ph>
                     <codeph>SPARK_APP_LOAD_MODE </codeph>
                  </ph>is either OPS or DEV mode, and if not explicitly specified defaults to OPS mode. For details on
                  application loading modes, see <xref
                     href="#FCFGHGGB/Part3:InstallUnravelSparkSensoronNeworExistingQuboleSparkCluster-Appendix"
                     >Appendix</xref>.</p>
               <p>
                  <ph>
                     <ph>
                        <ph>
                           <ph>
                              <ph>
                                 <ph>
                                    <codeph>
                                       <ph>WRAPPED_SCRIPT</ph>
                                    </codeph>
                                 </ph>
                              </ph>
                           </ph>
                        </ph>
                     </ph>
                  </ph> is the full S3 path to your original bootstrap script. Your bootstrap script is invoked from <ph>
                     <codeph>unravel_qubole_bootstrap.sh</codeph>
                  </ph>.</p>
            </li>
            <li>
               <p outputclass="auto-cursor-target">Confirm that the <codeph>unravel_es</codeph> service is
                  installed:</p>
               <ol>
                  <li>
                     <p outputclass="auto-cursor-target">Open an SSH session to the Qubole master node.</p>
                  </li>
                  <li>
                     <p outputclass="auto-cursor-target">Run this command to check that the unravel_es service has been
                        started:</p>
                     <codeblock outputclass="syntaxhighlighter-pre"># ps -aux | grep unravel_es</codeblock>
                  </li>
               </ol>
            </li>
         </ol>
         <p>(Optional) Add Unravel Spark Instrumentation to an Existing Qubole Spark Cluster</p>
         <ol>
            <li>Ensure that you have configured s3 read-only credentials
                  in <codeph>/usr/local/unravel/etc/s3ro.properties</codeph> for Unravel, as described in <xref
                  href="#FCFGHGGB/Part3:InstallUnravelSparkSensoronNeworExistingQuboleSparkCluster-configure_s3ro">steps
                  1 and 2 above</xref>.</li>
            <li>
               <p>Obtain following essential Spark version files from Unravel Server:</p>
               <ol>
                  <li>
                     <p>To obtain Spark version 1.6.x zip file:</p>
                     <codeblock outputclass="syntaxhighlighter-pre"># wget http://{UNRAVEL_HOST_IP}:3000/hh/unravel-sensor-for-spark-bin-1.6.zip
</codeblock>
                  </li>
                  <li>
                     <p>To obtain Spark version 2.0.x zip file:</p>
                     <codeblock outputclass="syntaxhighlighter-pre"># wget http://{UNRAVEL_HOST_IP}:3000/hh/unravel-sensor-for-spark-bin-2.0.zip</codeblock>
                     <ph outputclass="aui-icon aui-icon-small aui-iconfont-approve confluence-information-macro-icon"/>
                     <p>
                        <ph>Unzip the archive </ph>
                        <codeph>
                           <ph>unravel-sensor-for-spark-bin-1.6.zip</ph>
                        </codeph>
                        <ph> and ensure via the bootstrap action that the included jars are deployed on Qubole nodes at <ph>
                              <ph>
                                 <ph>
                                    <codeph>PATH_TO_SENSOR_JARS</codeph>
                                 </ph>
                              </ph>
                           </ph>
                        </ph>
                        <ph> </ph>
                        <ph>which is used in the configuration settings outlined in step 4. </ph>
                     </p>
                  </li>
               </ol>
            </li>
            <li>
               <p outputclass="auto-cursor-target">
                  <ph>
                     <ph>Obtain EMR jar files and snippet script that should be added to the bootstrap action to start
                        the unravel_es process:</ph>
                  </ph>
                  <ph>
                     <ph>
                        <ph/>
                     </ph>
                  </ph>
               </p>
               <codeblock outputclass="syntaxhighlighter-pre">
#wget http://{UNRAVEL_HOST_IP}:3000/hh/unraveldata-clients/snippets/run-es.sh
#wget http://{UNRAVEL_HOST_IP}:3000/hh/unravel-emr-sensor.jar
</codeblock>
               <ph outputclass="aui-icon aui-icon-small aui-iconfont-approve confluence-information-macro-icon"/>
               <p>
                  <ph>Ensure that <codeph>unravel-emr-sensor.jar</codeph>
                  </ph>
                  <ph> is deployed on the Qubole nodes via the bootstrap action. Preferably, deploy <ph>
                        <codeph>unravel-emr-sensor.jar</codeph>
                     </ph>
                  </ph>
                  <ph>at the same path of <ph>
                        <ph>
                           <ph>
                              <ph>
                                 <codeph>PATH_TO_SENSOR_JARS</codeph>
                              </ph>
                           </ph>
                        </ph>
                     </ph>
                  </ph>
                  <ph> </ph>
                  <ph>as used above.</ph>
               </p>
            </li>
            <li>
               <p outputclass="auto-cursor-target">Edit <codeph>run-es.sh</codeph> snippet script to customize following
                  two parameters to fit into your Qubole Spark environment:</p>
               <codeblock outputclass="syntaxhighlighter-pre"># Replace following two parameters into your Qubole Spark environment #
UNRAVEL_HOST={UNRAVEL_HOST_IP}
UNRAVEL_EMR_SENSOR_JAR={PATH_TO_SENSOR_JARS}</codeblock>
               <p outputclass="auto-cursor-target">
                  <i/>
               </p>
            </li>
            <li>
               <p outputclass="auto-cursor-target">
                  <ph>
                     <ph>Spark configuration can be provided in the </ph>
                     <ph>Qubole console</ph>
                     <ph> at bootstrap or directly inside </ph>
                     <ph>
                        <ph>
                           <codeph>spark-defaults.conf</codeph>
                        </ph>
                     </ph>
                     <ph> configuration file, if the cluster is already started. </ph>
                  </ph>
               </p>
               <codeblock outputclass="syntaxhighlighter-pre">spark.unravel.server.hostport {UNRAVEL_HOST_IP}:4043
spark.driver.extraJavaOptions -javaagent:{PATH_TO_SENSOR_JARS}/btrace-agent.jar=bootClassPath={PATH_TO_SENSOR_JARS}/unravel-boot.jar,systemClassPath=&lt;PATH_TO_SENSOR_JARS&gt;/unravel-sys.jar,script=DriverProbe.class:SQLProbe.class -Dcom.sun.btrace.FileClient.flush=-1
spark.executor.extraJavaOptions -javaagent:{PATH_TO_SENSOR_JARS}/btrace-agent.jar=bootClassPath={PATH_TO_SENSOR_JARS}/unravel-boot.jar,systemClassPath={PATH_TO_SENSOR_JARS}/unravel-sys.jar,script=ExecutorProbe.class -Dcom.sun.btrace.FileClient.flush=-1</codeblock>
            </li>
            <li>
               <p outputclass="auto-cursor-target">Edit <codeph>zeppelin-env.sh</codeph> by appending the following
                  values to <codeph>ZEPPELIN_JAVA_OPTS</codeph> as follows:</p>
               <codeblock outputclass="syntaxhighlighter-pre">export ZEPPELIN_JAVA_OPTS="-Dcom.sun.btrace.FileClient.flush=-1 -javaagent:{PATH_TO_SENSOR_JARS}/btrace-agent.jar=bootClassPath={PATH_TO_SENSOR_JARS}/unravel-boot.jar,systemClassPath={PATH_TO_SENSOR_JARS}/unravel-sys.jar,script=DriverProbe.class:SQLProbe.class"</codeblock>
               <p outputclass="auto-cursor-target">
                  <i/>
               </p>
               <ph outputclass="aui-icon aui-icon-small aui-iconfont-approve confluence-information-macro-icon"/>
               <p>The Zeppelin configuration is located at <codeph>/usr/lib/zeppelin/conf/zeppelin-env.sh</codeph>.</p>
            </li>
         </ol>
         <p/>
         <p>
            <ph outputclass="confluence-anchor-link"/>Appendix</p>
         <p>
            <b>Application Loading Modes for Spark Applications: OPS, DEV, and BATCH</b>
         </p>
         <p>There are three modes in which Spark applications can be loaded into Unravel Web UI:</p>
         <ul>
            <li>OPS mode shows applications in the UI after the application is done.</li>
            <li>DEV mode shows applications in the UI as soon as the first job of the Spark application completes.</li>
            <li>BATCH mode loads applications for which the sensor was not enabled at the time the application has been run.  <ph>
                  <ph> </ph>
               </ph>
            </li>
         </ul>
         <p>You can specify the application load mode for the bootstrap script by setting
               <codeph>SPARK_APP_LOAD_MODE</codeph> to <codeph>OPS</codeph> or <codeph>DEV</codeph>. By default, if not
            explicitly specified, <codeph>SPARK_APP_LOAD_MODE</codeph> is <codeph>OPS</codeph>. All three modes can
            coexist in the same Unravel Server. For example, all Spark applications from Qubole cluster A can be loaded
            in OPS mode, all Spark applications from Qubole cluster B can be loaded in DEV mode, and all Spark
            applications from Qubole cluster C can be loaded in BATCH mode.</p>
         <p>
            <b>When to Use Which Mode</b>
         </p>
         <ul>
            <li>
               <p>Unravel recommends using OPS mode as the cluster-side default for all Qubole clusters. The OPS mode
                  has been rigorously benchmarked to have less than 1.3% CPU and memory overhead. Both the OPS and DEV
                  modes use the Unravel Spark sensor, which is enabled via modifications to <ph>
                     <codeph>spark.driver.extraJavaOptions</codeph>.</ph> The key difference is that OPS mode sets <codeph>
                     <ph>-Dcom.unraveldata.spark.sensor.disableLiveUpdates=true</ph>
                  </codeph> while DEV mode sets<ph>
                     <codeph> -Dcom.unraveldata.spark.sensor.disableLiveUpdates=false</codeph> (false is the
                     default).</ph>
               </p>
            </li>
         </ul>
         <ul>
            <li>
               <p>DEV mode is useful during Spark application development. This mode shows a Spark application as soon
                  as the first Spark job of the application finishes. For long running applications, this functionality
                  is useful, as the application is shown in the UI while the application is running. In addition, DEV
                  mode shows applications even when the Spark event log is not being persisted to HDFS or S3. This is an
                  advantage in situations like Spark on Mesos.</p>
            </li>
         </ul>
         <ul>
            <li>
               <p>In a Qubole cluster that is using OPS mode as the default, DEV mode can be obtained for individual
                  Spark applications by overriding <ph>
                     <codeph>spark.driver.extraJavaOptions</codeph> to include
                        <codeph>-Dcom.unraveldata.spark.sensor.disableLiveUpdates=false</codeph>.</ph>
               </p>
            </li>
         </ul>
         <ul>
            <li>
               <p>BATCH mode is always on and does not interfere with application performance in any way since the
                  loading is entirely outside the application execution path. For details see the next section.</p>
            </li>
         </ul>
         <p/>
         <p>
            <b>Loading Applications in Batch Mode</b>
         </p>
         <p>In order to load Spark apps in BATCH mode, Unravel Server must pull the Spark event log file either from S3
            or from HDFS. The data collected in the UI is less detailed than when  Unravel Sensor is enabled (for
            instance, detailed resource usage metrics are unavailable). The BATCH mode of operation is helpful to load
            all of the applications that have been run in the past, before Unravel Sensor was installed. To enable the
            batch mode, add the following property to <codeph>/usr/local/unravel/etc/unravel.properties</codeph> and
            restart the Spark worker daemon(s) as listed earlier:</p>
         <codeblock outputclass="syntaxhighlighter-pre">com.unraveldata.spark.eventlog.location=hdfs://NAMENODE_IP_PORT/user/spark/applicationHistory/</codeblock>
         <note>
            <p>Currently, only one event log location is supported.</p>
         </note>
      </context>
   </taskbody>
</task>
